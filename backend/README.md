# Backend - Intelligent Research Assistant

## ğŸš€ DÃ©marrage Rapide

### Option 1: DÃ©marrage Local (RecommandÃ© pour le dÃ©veloppement)

1. **Installer les dÃ©pendances**
   ```bash
   cd backend
   pip install -r requirements.txt
   ```

2. **Configurer l'environnement**
   ```bash
   # Depuis la racine du projet
   cp .env.example .env
   # Ã‰ditez .env et ajoutez votre GOOGLE_API_KEY
   ```

3. **DÃ©marrer le serveur**
   ```bash
   # Option A: Avec le script Python
   python start_backend.py
   
   # Option B: Directement avec uvicorn
   uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
   ```

4. **AccÃ©der Ã  l'application**
   - API: http://localhost:8000
   - Documentation: http://localhost:8000/docs
   - Health Check: http://localhost:8000/health

### Option 2: Avec Docker

```bash
# Depuis la racine du projet
docker-compose up --build backend
```

## ğŸ”§ RÃ©solution des ProblÃ¨mes

### ProblÃ¨me: Erreur AttributeError avec torch/sentence-transformers

**SymptÃ´me:**
```
AttributeError: module 'torch.utils' has no attribute '_register_pytree_node'
```

**Solution:**
Les versions de `torch` et `sentence-transformers` ont Ã©tÃ© mises Ã  jour pour Ãªtre compatibles:
- torch: 2.1.2 â†’ 2.2.0
- sentence-transformers: 2.3.1 â†’ 2.6.0

Reconstruisez l'image Docker:
```bash
docker-compose down
docker-compose build --no-cache backend
docker-compose up backend
```

### ProblÃ¨me: Le backend ne dÃ©marre pas

**VÃ©rifications:**

1. **ClÃ© API Google Gemini**
   ```bash
   # VÃ©rifiez que votre .env contient une vraie clÃ© API
   cat ../.env | grep GOOGLE_API_KEY
   ```

2. **DÃ©pendances Python**
   ```bash
   pip list | grep -E "fastapi|uvicorn|torch|sentence-transformers"
   ```

3. **Port dÃ©jÃ  utilisÃ©**
   ```bash
   # Windows
   netstat -ano | findstr :8000
   
   # Linux/Mac
   lsof -i :8000
   ```

### ProblÃ¨me: Timeout lors de l'installation des dÃ©pendances

**Solution:**
Utilisez la version simplifiÃ©e pour tester:
```bash
pip install -r requirements-simple.txt
```

Ou installez les dÃ©pendances lourdes sÃ©parÃ©ment:
```bash
# 1. PyTorch CPU (plus lÃ©ger)
pip install torch==2.2.0 --index-url https://download.pytorch.org/whl/cpu

# 2. Sentence Transformers
pip install sentence-transformers==2.6.0

# 3. Autres dÃ©pendances
pip install -r requirements.txt
```

### ProblÃ¨me: Erreur de mÃ©moire lors du build Docker

**Solution:**
Augmentez la mÃ©moire allouÃ©e Ã  Docker:
- Docker Desktop â†’ Settings â†’ Resources â†’ Memory: 4GB minimum

Ou utilisez le Dockerfile optimisÃ©:
```bash
docker build -f Dockerfile.optimized -t research-assistant-backend .
```

## ğŸ“¦ Versions des DÃ©pendances

### Principales DÃ©pendances

| Package | Version | Description |
|---------|---------|-------------|
| FastAPI | 0.109.0 | Framework web |
| Uvicorn | 0.27.0 | Serveur ASGI |
| PyTorch | 2.2.0 | ML Framework (CPU) |
| Sentence-Transformers | 2.6.0 | Embeddings |
| ChromaDB | 0.4.22 | Vector Store |
| LangChain | >=0.1.0 | LLM Framework |
| Google Generative AI | 0.4.0 | Gemini API |

### CompatibilitÃ©

- Python: 3.11+
- OS: Windows, Linux, macOS
- Docker: 20.10+

## ğŸ” Configuration

### Variables d'Environnement

CrÃ©ez un fichier `.env` Ã  la racine du projet:

```env
# Google Gemini API
GOOGLE_API_KEY=votre_clÃ©_api_ici

# Vector Store
VECTOR_STORE_TYPE=chroma
CHROMA_PERSIST_DIRECTORY=./data/vector_store

# Embeddings
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2
EMBEDDING_DEVICE=cpu

# API
API_HOST=0.0.0.0
API_PORT=8000
DEBUG=false

# CORS
ALLOWED_ORIGINS=["http://localhost:3000", "http://127.0.0.1:3000"]
```

## ğŸ§ª Tests

```bash
# Tests unitaires
pytest tests/ -v

# Tests avec couverture
pytest tests/ --cov=app --cov-report=html

# Test de santÃ© de l'API
curl http://localhost:8000/health/
```

## ğŸ“ Structure du Projet

```
backend/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/           # Endpoints API
â”‚   â”œâ”€â”€ core/          # Configuration et utilitaires
â”‚   â”œâ”€â”€ models/        # ModÃ¨les de donnÃ©es
â”‚   â”œâ”€â”€ services/      # Logique mÃ©tier
â”‚   â””â”€â”€ main.py        # Point d'entrÃ©e
â”œâ”€â”€ data/              # DonnÃ©es et stockage
â”œâ”€â”€ tests/             # Tests
â”œâ”€â”€ requirements.txt   # DÃ©pendances complÃ¨tes
â”œâ”€â”€ requirements-simple.txt  # DÃ©pendances minimales
â”œâ”€â”€ Dockerfile         # Image Docker
â”œâ”€â”€ Dockerfile.optimized     # Image Docker optimisÃ©e
â””â”€â”€ start_backend.py   # Script de dÃ©marrage
```

## ğŸ†˜ Support

Si vous rencontrez des problÃ¨mes:

1. VÃ©rifiez les logs: `docker-compose logs backend`
2. Consultez la documentation: http://localhost:8000/docs
3. VÃ©rifiez les issues GitHub
4. CrÃ©ez une nouvelle issue avec les dÃ©tails de l'erreur

## ğŸ“š Ressources

- [FastAPI Documentation](https://fastapi.tiangolo.com/)
- [Google Gemini API](https://ai.google.dev/)
- [LangChain Documentation](https://python.langchain.com/)
- [ChromaDB Documentation](https://docs.trychroma.com/)
